Structure Streaming:
 Streaming processing на основе Spark SQL. Главная идея в том, что Streaming построен на основе Dataset и Dataframe. Вычисления происходят так же на там же spark SQL движке, что приводит к импруву при выполнении. Exactly-one и fault-tolerant система. По дефолту Structure Streaming использует micro-batch для доставки собщений, гарантируя exactly-once, fault-tolerance. С версии Spark 2.3 было введено Continuous Processing, который постоянно поставляет сообщения с гарантией at-least-once.
 К Structure Streaming можно относиться как к таблице, которая постоянно насыщается данными[Input Table]. По сути введена концепция того, что вы оперируете на данных, как на обычных DF или DS.
 Input table:
  1) Каждые пришедшие новые данные, рассматриваются как новая row.
 Жизненный цикл SS: Input table -> Computation on input table -> Result table -> output.

 OutputMode:
  1) Append()[Без агрегаций] - Добавляет только новые строчки в sink.
  2) Complete()[С Агрегацией] - Добавляет все строчки в sink.
  3) Update()[И то и то] - Добавляет только обновленные строчки в sink, а иначе действует как Append при отсутствии агрегаций.

 Общая структура такова, что читаются данные из source, считаются и записываются в Result table, а затем Source data дискардится. Spark Streaming держит минимальное количество промежуточных данных.
 
 Event-time - время, когда были созданы данные, не путать с Procesing-time - время, когда данные были приняты Spark. 

 Fault-tolerance - с ней Spark справляется путем того, что он перезапускает или перерабатывает данные. Предполагается что каждый source имеет offset. Движок использует checkpoint and write-ahed log для записи данных которые будут записаны на каждый trigger. Sink в свою очередь гарантирует idempotent, таким образом есть end-to-end exactly-once semantics.
 
 Читать данные можно из (out of the box): File Source [text, CSV, JSON, ORC, Parquet], Kafka source, Socket source (for testing) and Rate source (for testing). Некторые source не fault-tolerance, так как не поддерживают Spark checkpoint. 

 Sources as files по дефолту на поддерживают наследование схемы. Это уверяет в том, что согласованная схема будет использоваться, даже в случае ошибок.
 Partitioning - это когда директории приставляются в виде /key=value/...  и Spark на базе колонок пользователя может разместить данные сам в соответсвующие части. !!! Важно помнить, что менять структуру key=value нельзя после того как запустилось Stream приложение, можно только добавлять.

 На SS доступны почти все те же самые операции что на DS and on DF.

 Window:
  Event-time позволяет нам выполнять window операции, такие как, количество эвентов за минуту. По идеи, Window операции, то же самое, что и обычный group by with agreagation, можно считать каждый window группой, но записи может принадлежать разным группам. Более того, из-за того что Structure Streaming имеет полный контроль над Result table, мы можем либо сохранить, либо выкинуть запоздавшие данные, это называется watermark.
  При создании Window параметризуется время, определяющее как часто и на сколько нужно сдавать окна, и имя колонки.
  val windowedCounts = words.groupBy(
    window($"timestamp", "10 minutes", "5 minutes"),
    $"word"
  ).count()
  Watermarks:
   Позволяет трекать event time приходящих данных и чистить старое состояние если то потребуется. Для определения Watermarks мы должны указать event-time колонку и время, через которое состояние будет очищаться из памяти: df/ds.withWatermark("timestamp", "10 minutes"). Все получается таким образом, что данные попавшие в рамки watermark агрегируются к своему окну, а данные не попавшие в watermark просто удаляются.
   В зависимости от output mode, мы либо Update Result table при каждом тригере, либо Append.
   Для использования watermarks:
    1) Использовать output mode: Append or Update.
    2) Агрегация должна иметь либо event-time column или on the event-time column.
    3) withWatermark должно быть вызвано на той же колонке, что и groupBy.
    4) withWatermark должно быть вызвано до агрегаций для watermark.
  И последнее, watermark с задержкой в 2 часа, гарантирует что данные, пришедшие менее чем за 2 часа, будут обрабатываться, а иначе обратное не гарантируется, те, данные пришедшие более чем за 2 часа, не факт что удаляться, но чем более время задержки, тем больше шанс того что они удаться. 

 Join так же присутствуют, и их результат ничем не отличается от пакетных джоинов. Джоинить как можно статические данные, так и другие стримы. Присутствует множество видов join. Stream-stream работает хорошо, но есть проблема, так как данные могут приходить не согласованно, она решается автоматически, тем, что прошедшие данные храняться в буфере. Время хранения моно настроить с помощью watermarks. 
  Inner-join:
   При работе с ним нужно учитывать то что количество данных которое хранится в памяти будет постоянно расти, так как множество колонок из прошлого будет совпадать с новыми колонками. Для того чтобы это избежать, нужно добавить условие, которое запретит совпадение бесконечно старых колонок с новыми:
    1) Определить watermark для обозначения того, на сколько сильно могут задержаться данные.
    2) Определить условие, при котором движок будет понимать, что данные уже устарели и значит их не нужно использовать.
  Outer join:
   Пока для Inner Join использование ограничение является не обязательным, для outer join, вы должны его использовать. Для того чтобы в будущем движок для генерации NULL знал, когда Input ROW не будет совпадать с чем-либо в будущем. Есть еще одно ограничение, говорящие о том, что при использовании Outer join, важно понимать то, что если таблица, которая участвует в join не получила данные, ждущая таблица, выведет результат с задержкой.
  Последние детали о join:
   1) Мб каскадный: df1.join(df2, ...).join(df3, ...).join(df4, ....)
   2) Запросы можно выполнять только в Append режиме.
   3) Вы не можете использовать другие non-map-like операции до join.
   
















