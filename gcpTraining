BigQuery:
	1) Можно создавать функции изнутри
	2) Сожно делать запросы к экстерна сторам(федерал риквест)
	3) Project -> Dataset -> Tables
	4) Все инкриптится
	5) Вью - еще один способы защиты данных
	6) Используется для анализа, ML и репортинга
	7) Рассчитан на анализ огромного количества данных
	8) Платить можно как и за запросы, так и за объем данных
	9) Денормализованная таблица, порождает большую производительность(схема)
	10) Присутствует поддержка такого типа полей, как Nested and Repeated
	11) Тип данных Struct (event.time, event.status etc.) (Как преджоин таблиц)
	12) Тип данных Array (event.time, event.status etc.) (Как набор данных)
	13) Коломно-ориентированный, значит не подгружает весь датасет при поиске
	14) Partitions разбивает колонну на части, что делать поиск проще
	15) Из-за разделение колноки, увеличивается количество метаданых
	16) BigQuery автоматически сортирует колонки помеченные кластерными
	17) Так же имеет смысл порядок в котором находятся кластеризуемые колонки
	18) Помогает решить проблемы связанные с качеством данных через SQL.
	19) Батч данные предпочтительнее чем стрим
	20) Поддерживает GIS функции (геолокация и тд)
	21) Прославляется денормализация
	22) GeoViz отображает точки на карте 
	23) Поддерживает WITH, который сохраняет в себе всегда исполняемы SELECT
	24) С помощью LAG() мы можем вернуться к предыдущему значению
	25) Кеширование применяется при схожести запросов
	26) Кеширование на происходит при неопределенных запросах
	27) WITH and VIEW не кешируются
	28) BI мб использован для кеширования таблиц
	29) Нужно избегать джоинов
	30) Вместо селфи Джон использовать агрегацию
	31) Минимизируйте сортировку так как она исполнятся на 1 воркере
	32) В джоинах большую таблицу слева
	33) Cортировку производить в последнюю очередь
	34) Фильтровать раньше и чаще
	35) BQ ML позволяет писать ML задачи на SQL-like синтексе 
	36) log_reg model служит для выбора категории (линейный) (прилет самолета)
	37) ML.EVALUATE(*model*) оценивает модель по показателям
	38) din_classifier более сложны классификатор (не линейный) (износ машины)
	39) lineral_reg используется для линейного предсказания (линейный) (t/f)
	40) dnn_regresor -||- (не линейный)
	41) Можно загружать модели из Tensorflow
	42) matrix_factorization модель для рекомендаций 

BigTable:
	1) Более быстрая чем BigQuery
	2) NoSQL синтакс
	3) Не подходит для больших файлов
	4) Создан для решения спецефических задач на скорость
	5) Подходят не для структурированных дат
	6) Хранятся данные в файловой системе под названием Colossus
	7) Строится на файлах, которые хранят таблицы и метаинформацию
	8) Может манипулировать всем в своей системе
	9) Разворачивается на многих машинах 
	10) Может существовать только один индекс и данные сортируются по индексу
	11) Почти нет стандартных операторов, из чего следует, название NoSQL
	12) При проектировки нужно выбирать такой row key, который чаще вызывается
	13) Данные мб организованы по фамилиям 
	14) Отсутсвие значение не занимает никакой памяти, поэтому делай большую таблицу
	15) Позволяет работать с стриминговыми данными

Storage:
	1) DataLakes
	2) Хранит в себе все виды данных (объекты)
	3) Backet -> Object
	4) Все так же отлично инкриптится, как объекты, так и баккеты

Dataproc:
	1) Под капотом машина с Hadoop c Spark и многими другими приблудами
	2) Хранить данные нельзя, так как постоянно меняются кластеры 
	3) Можно создавать и удалять кластеры
	4) Легко интегрируемая с хранилищами
	5) Легко создавать кластеры по нуждам
	6) Работы по дефолту не перезапускаемые
	7) Нельзя их задавать через интерфейс
	8) Самой главной выгодой является разделение выполнения и хранения
	9) Хранить в HDFS стоит только когда есть много метадаты и переименовываются папки
	10) YAML содержит шаблон создания hadoop процесса
	11) StackDriver используется для мониторинга процессов Hadoop 

DataFusion:
	1) Продукт для графического построения потоков
	2) Юзается для трансформирования, ремува дубликатов, монитора и тд
	3) Под капотом работа достигается с помощью Dataproc
	4) Если есть свой Dataproc, DataFusion можно запустить по верх него
	5) Содержит кучу сервисов, управляющих потоком данных
	6) Wrangler - можем сконвертировать данные в поток данных
	7) Data Pipeline - для строительства сложных воркфлоу
	8) Rules Engin - для мониторинг и планирования ворк флоу
	9) Metadata Aggregator - Создание метадаты и дата  словарей
	10) Пайплайны билдятся с помощью DAG
	11) ИСПОЛЬЗУЕТСЯ ДЛЯ ОБРАБОТКИ БАТЧ ПОТОКОВ
	12) Можно просматривать ход филда (откуда/куда)

DataComposer:
	1) Строит пайплайны с любым сервисом gcp
	2) Управляется с помощью Apache airflow
	3) Идея в том, чтобы соединять абсолютно разные задачки
	4) Есть куча встроенных операторов связанных с GCP

Dataflow:
	1) Полностью управляемый процесс на основе Apache Beam для построения pipeline
	2) Пайплайны могут быть бач и стрим, причем код одинаковый
	3) Служит для обработки дата процесов
	4) По структуре схож с Airflow
	5) Apache Beam решает то как будет выполнятся та или иная задача
	6) Dataflow решает то как будут связаны эти задачи
	7) Постоянно происходит оптимизация 
	8) Окна группируют стриминговые элементы в группы по признаку (i.e. Времени)
	9) Watermark - техника для рассвета времени между приходом элемента и его времени

DataCatalog:
	1) Знать метаданные данных (от куда, какого качества, сможем ли мы его обработать)
Это может понадобится для дальнейшей обработке данных, при получении странных результатов
Labels(BigQuery) на датасет, таблицу, вью может помочь организовать ресурсы

DataStudio:
	1) Визуализирует данные

Pub/Sub:
	1) Асинхронная шина сообщений
	2) По сути считывает данные с источника и без преобразования посылает подписчику
	3) Принцип работы как у jms
	4) Availabilty, Durability, Scalability
	5) Имеется возможность хранить сообщения до того как их сможешь прочитать (буффер)
	6) Основано на топиках и подписках 
	7) Поддерживает две, push и pull модели
	8) pull - подписчики посылают запрос на получение сообщений, и обратно ack
	9) push - топик сам посылает подписчикам сообщения, и получает обратно ack (HTTP)
	10) Если ack не был получен, сообщение еще раз пересылается 
	11) Sub может получать как синхронно так и асинхронно
	12) Сообщения могут приходить не в порядке
	13) Могут приходить дубликаты
	14) Подписчики получают сообщения только после того как они были подписаны

AI Platform:
	1) Сервис на основе TensorFlow
	2) Позволяет писать пользователям свои алгоритмы для ML

Cloud AutoML:
	1) Сервис для которого нужно лишь данные, писать код не надо
	2) Модели которые не используются, удаляются через время

Pre-trained ML model:
	1) Набор натренированных моделей, которые юзер может использовать для своих нужд
	2) Дает хорошие результаты, только если данные пользователя подходят

CloudAI:
	1) Авторасширяемая, трансформирующая данные на входе и тд
	2) Поддерживает Notebooks

KubeFlow:
	1) Пакует ML задачи для Kubernetes
	2) Служит для строительства BL пайплайнов
	3) Похож на DataComposer
	4) Можно использовать Notebook для дефайна workflow
	5) Пишутся пайплайны с помощью Python SDK
	6) Можно упаковывать в пакеты пайплайны, для дальнейшего реюза 

AI Hub:
	1) Хранлище с готовыми пайплайнами, датасетами и тд

-------------------------------------------------------------------------

Требования качества данных: Validity(Подходит к требованиям бизнеса),
Accuracity(Точность данных),
Completeness(Не должно быть пропущенных значений),
Consistency(За уникальность данных),
Uniformity(Однообразность данных)
Эти требования независимы 

EL -> Data -> BigQuery
ELT -> Data -> BigQuery -> BigQuery
ETL -> Data -> Dataflow, Dataproc -> BigQuery

DataBeam компоненты:
	1) PCollection хранит данные, которые будут обработаны. Неизменяемый
	2) PTransforms действия (код) над коллекцией данных. Содержит I -> T -> O
	3) Pipeline Runners дом пайплайнов (Dataflow, VM, etc) 
	
Machine Learning:
	1) ML строится на стандартных алгоритмах, которые могу быть натрененрованы на разные вещи, основываясь на входных данных 
	2) Model - случай, для которого тренируется алгоритм
	3) Первый шаг в ML дать как можно больше модели, чтобы она натренировалась
	4) Label - корректные ответы для входных данных
	5) AI(физика) -> ML(разделы) -> DL(глубокие подразделы)
	6) Для ML отлично подходит Notebook(Jupiter) для построение пайплайнов
	7) ML отлично интегрируется с другими сервисами GCP

