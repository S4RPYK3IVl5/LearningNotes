BigQuery:
	1) Можно создавать функции изнутри
	2) Сожно делать запросы к экстерна сторам(федерал риквест)
	3) Project -> Dataset -> Tables
	4) Все инкриптится
	5) Вью - еще один способы защиты данных
	6) Используется для анализа, ML и репортинга
	7) Рассчитан на анализ огромного количества данных
	8) Платить можно как и за запросы, так и за объем данных
	9) Денормализованная таблица, порождает большую производительность(схема)
	10) Присутствует поддержка такого типа полей, как Nested and Repeated
	11) Тип данных Struct (event.time, event.status etc.) (Как преджоин таблиц)
	12) Тип данных Array (event.time, event.status etc.) (Как набор данных)
	13) Коломно-ориентированный, значит не подгружает весь датасет при поиске
	14) Partitions разбивает колонну на части, что делать поиск проще
	15) Из-за разделение колноки, увеличивается количество метаданых
	16) BigQuery автоматически сортирует колонки помеченные кластерными
	17) Так же имеет смысл порядок в котором находятся кластеризуемые колонки
	18) Помогает решить проблемы связанные с качеством данных через SQL.
	19) Батч данные предпочтительнее чем стрим
	20) Поддерживает GIS функции (геолокация и тд)
	21) Прославляется денормализация
	22) GeoViz отображает точки на карте 
	23) Поддерживает WITH, который сохраняет в себе всегда исполняемы SELECT
	24) С помощью LAG() мы можем вернуться к предыдущему значению
	25) Кеширование применяется при схожести запросов
	26) Кеширование на происходит при неопределенных запросах
	27) WITH and VIEW не кешируются
	28) BI мб использован для кеширования таблиц
	29) Нужно избегать джоинов
	30) Вместо селфи Джон использовать агрегацию
	31) Минимизируйте сортировку так как она исполнятся на 1 воркере
	32) В джоинах большую таблицу слева
	33) Cортировку производить в последнюю очередь
	34) Фильтровать раньше и чаще
	35) BQ ML позволяет писать ML задачи на SQL-like синтексе 
	36) log_reg model служит для выбора категории (линейный) (прилет самолета)
	37) ML.EVALUATE(*model*) оценивает модель по показателям
	38) din_classifier более сложны классификатор (не линейный) (износ машины)
	39) lineral_reg используется для линейного предсказания (линейный) (t/f)
	40) dnn_regresor -||- (не линейный)
	41) Можно загружать модели из Tensorflow
	42) matrix_factorization модель для рекомендаций 

BigTable:
	1) Более быстрая чем BigQuery
	2) NoSQL синтакс
	3) Не подходит для больших файлов
	4) Создан для решения спецефических задач на скорость
	5) Подходят не для структурированных дат
	6) Хранятся данные в файловой системе под названием Colossus
	7) Строится на файлах, которые хранят таблицы и метаинформацию
	8) Может манипулировать всем в своей системе
	9) Разворачивается на многих машинах 
	10) Может существовать только один индекс и данные сортируются по индексу
	11) Почти нет стандартных операторов, из чего следует, название NoSQL
	12) При проектировки нужно выбирать такой row key, который чаще вызывается
	13) Данные мб организованы по фамилиям 
	14) Отсутсвие значение не занимает никакой памяти, поэтому делай большую таблицу
	15) Позволяет работать с стриминговыми данными

Storage:
	1) DataLakes
	2) Хранит в себе все виды данных (объекты)
	3) Backet -> Object
	4) Все так же отлично инкриптится, как объекты, так и баккеты

Dataproc:
	1) Под капотом машина с Hadoop c Spark и многими другими приблудами
	2) Хранить данные нельзя, так как постоянно меняются кластеры 
	3) Можно создавать и удалять кластеры
	4) Легко интегрируемая с хранилищами
	5) Легко создавать кластеры по нуждам
	6) Работы по дефолту не перезапускаемые
	7) Нельзя их задавать через интерфейс
	8) Самой главной выгодой является разделение выполнения и хранения
	9) Хранить в HDFS стоит только когда есть много метадаты и переименовываются папки
	10) YAML содержит шаблон создания hadoop процесса
	11) StackDriver используется для мониторинга процессов Hadoop 

DataFusion:
	1) Продукт для графического построения потоков
	2) Юзается для трансформирования, ремува дубликатов, монитора и тд
	3) Под капотом работа достигается с помощью Dataproc
	4) Если есть свой Dataproc, DataFusion можно запустить по верх него
	5) Содержит кучу сервисов, управляющих потоком данных
	6) Wrangler - можем сконвертировать данные в поток данных
	7) Data Pipeline - для строительства сложных воркфлоу
	8) Rules Engin - для мониторинг и планирования ворк флоу
	9) Metadata Aggregator - Создание метадаты и дата  словарей
	10) Пайплайны билдятся с помощью DAG
	11) ИСПОЛЬЗУЕТСЯ ДЛЯ ОБРАБОТКИ БАТЧ ПОТОКОВ
	12) Можно просматривать ход филда (откуда/куда)

DataComposer:
	1) Строит пайплайны с любым сервисом gcp
	2) Управляется с помощью Apache airflow
	3) Идея в том, чтобы соединять абсолютно разные задачки
	4) Есть куча встроенных операторов связанных с GCP

Dataflow:
	1) Полностью управляемый процесс на основе Apache Beam для построения pipeline
	2) Пайплайны могут быть бач и стрим, причем код одинаковый
	3) Служит для обработки дата процесов
	4) По структуре схож с Airflow
	5) Apache Beam решает то как будет выполнятся та или иная задача
	6) Dataflow решает то как будут связаны эти задачи
	7) Постоянно происходит оптимизация 
	8) Окна группируют стриминговые элементы в группы по признаку (i.e. Времени)
	9) Watermark - техника для рассвета времени между приходом элемента и его времени

DataCatalog:
	1) Знать метаданные данных (от куда, какого качества, сможем ли мы его обработать)
Это может понадобится для дальнейшей обработке данных, при получении странных результатов
Labels(BigQuery) на датасет, таблицу, вью может помочь организовать ресурсы

DataStudio:
	1) Визуализирует данные

Pub/Sub:
	1) Асинхронная шина сообщений
	2) По сути считывает данные с источника и без преобразования посылает подписчику
	3) Принцип работы как у jms
	4) Availabilty, Durability, Scalability
	5) Имеется возможность хранить сообщения до того как их сможешь прочитать (буффер)
	6) Основано на топиках и подписках 
	7) Поддерживает две, push и pull модели
	8) pull - подписчики посылают запрос на получение сообщений, и обратно ack
	9) push - топик сам посылает подписчикам сообщения, и получает обратно ack (HTTP)
	10) Если ack не был получен, сообщение еще раз пересылается 
	11) Sub может получать как синхронно так и асинхронно
	12) Сообщения могут приходить не в порядке
	13) Могут приходить дубликаты
	14) Подписчики получают сообщения только после того как они были подписаны

AI Platform:
	1) Сервис на основе TensorFlow
	2) Позволяет писать пользователям свои алгоритмы для ML

Cloud AutoML:
	1) Сервис для которого нужно лишь данные, писать код не надо
	2) Модели которые не используются, удаляются через время

Pre-trained ML model:
	1) Набор натренированных моделей, которые юзер может использовать для своих нужд
	2) Дает хорошие результаты, только если данные пользователя подходят

CloudAI:
	1) Авторасширяемая, трансформирующая данные на входе и тд
	2) Поддерживает Notebooks

KubeFlow:
	1) Пакует ML задачи для Kubernetes
	2) Служит для строительства BL пайплайнов
	3) Похож на DataComposer
	4) Можно использовать Notebook для дефайна workflow
	5) Пишутся пайплайны с помощью Python SDK
	6) Можно упаковывать в пакеты пайплайны, для дальнейшего реюза 

AI Hub:
	1) Хранлище с готовыми пайплайнами, датасетами и тд

-------------------------------------------------------------------------

Требования качества данных: Validity(Подходит к требованиям бизнеса),
Accuracity(Точность данных),
Completeness(Не должно быть пропущенных значений),
Consistency(За уникальность данных),
Uniformity(Однообразность данных)
Эти требования независимы 

EL -> Data -> BigQuery
ELT -> Data -> BigQuery -> BigQuery
ETL -> Data -> Dataflow, Dataproc -> BigQuery

DataBeam компоненты:
	1) PCollection хранит данные, которые будут обработаны. Неизменяемый
	2) PTransforms действия (код) над коллекцией данных. Содержит I -> T -> O
	3) Pipeline Runners дом пайплайнов (Dataflow, VM, etc) 
	
Machine Learning:
	1) ML строится на стандартных алгоритмах, которые могу быть натрененрованы на разные вещи, основываясь на входных данных 
	2) Model - случай, для которого тренируется алгоритм
	3) Первый шаг в ML дать как можно больше модели, чтобы она натренировалась
	4) Label - корректные ответы для входных данных
	5) AI(физика) -> ML(разделы) -> DL(глубокие подразделы)
	6) Для ML отлично подходит Notebook(Jupiter) для построение пайплайнов
	7) ML отлично интегрируется с другими сервисами GCP





GCP ADVANCED

BigQuery:
 У него идет разделение на project -> dataset -> table. BigQuery берет как деньги за хранение так и за запросы которые мы запускаем на этих данных. Не имеет значение то, сколько будет обрабатываться данных через LIMIT, важно лишь только то, что мы берем все колонки, а это значит что в независимости от LIMIT будут обрабатываться все колонки.
 Не нужно заботиться об индексах.
 Добавление слова distinct в случае count( distinct gender ) посчитает нам не все колонки, а только уникальные. NULL значения не считаются при подсчете count у какой-то определенной колонки. Он работает на все колонки сразу.
 WHERE как и обычно сортирует данные по какому-то показателю. При этом не уменьшает количество обрабатываемых данных. IN окружается круглыми скобками. Like statement позволяет поместить колонку под regular expr.
 cast - функция которая позволяет нам кастовать один тип к другому.
 extract - функция позволяющая доставать часы/минуты/секнды и другие составные из даты.
 С timestamp можно манипулировать так же как с int, > or < and etc.
 GROUP BY, HAVING имеет то же поведение что и всегда.
 JOIN такой же как и везде, при этом по дефолту INNER подразумевает INNER JOIN.
 Математические функции соответствуют стандарту SQL, возвращают null or NaN если приходя соответсвующие параметры.
 rand() - функция которая выводит случайное число
 Разница между datetime and timestamp следующая, datetime мы не можем кешировать и по нему индексировать. Так же для работы с ними есть свои специальные функции. Ex.: timestamp_diff and datetime_diff. 
 CASE
    WHEN *condition* THEN ... - обычный CASE statement в рамках Big Query.
    ...
    ELSE ...
 END AS ...
 ....
 The records can be in Avro, CSV, JSON (newline delimited only), ORC, or Parquet format. Export data from Datastore or Firestore and load the exported data into BigQuery. Load data from other Google services, such as Google Ad Manager and Google Ads

 Anti-patterns:
  Self-joins: Typically, self-joins are used to compute row-dependent relationships. The result of using a self-join is that it potentially doubles the number of output rows. This increase in output data can cause poor performance. Instead of using a self-join, use a window (analytic) function to reduce the number of additional bytes that are generated by the query.
  Data Skew: Partition skew, sometimes called data skew, is when data is partitioned into very unequally sized partitions. This creates an imbalance in the amount of data sent between slots. You can't share partitions between slots, so if one partition is especially large, it can slow down, or even crash the slot that processes the oversized. Best practice: If your query processes keys that are heavily skewed to a few values, filter your data as early as possible.
  Unbalanced joins: Data skew can also appear when you use JOIN clauses. Because BigQuery shuffles data on each side of the join, all data with the same join key goes to the same shard. This shuffling can overload the slot.
  Cross Join: Best practice: Avoid joins that generate more outputs than inputs. When a CROSS JOIN is required, pre-aggregate your data.
  DML statements that update or insert single rows: Best practice: Avoid point-specific DML statements (updating or inserting 1 row at a time). Batch your updates and inserts.
 
 Best practice: 
  Avoid SELECT *: 
  Sample data using preview options:
  Price your queries before running them:
  Using the query validator:
  Using the pricing calculator:
  Limit query costs by restricting the number of bytes billed:
  LIMIT doesn’t affect cost:
  View costs using a dashboard and query your audit logs:
  Partition data by date:
  Materialize query results in stages:
  Consider the cost of large result sets: Best practice: If you are writing large query results to a destination table, use the default table expiration time to remove the data when it's no longer needed.
  Use streaming inserts with caution: There is no charge for loading data into BigQuery. There is a charge, however, for streaming data into BigQuery.
 Так же приходиться платить за хранение данных.

DataProc:
 Главная цель - использовать манежить Hadoop кластер за тебя, предоставляя удобный UI. Быстро поднимается и более дешевый путь, чем делать все самому. Он интегрирован с другими GCP сервисами.
 Платить за сервис приходиться по следующей формуле: $0.010 * # of vCPUs * hourly duration. Но при этом, у нас происходит взятие денег посекундно. И по мимо этой цены, прийдется еще платить и за Compute Engine Instance, и за Engine Persistence Disks.
 AccessControl:
  Для юзеров доступны только Viewer or Editor mode. Viewer может только смотреть на кластер, Джобы и операции, но не может создать/удалять и джобы и кластер. Editor может делать и то и другое. Такие разрешения применимы на уровне проекта. Назначение ролей можно произвести в IAM, там уже назначения либо на уровне Dataproc, либо на уровне Project menu. Worker - это роль, которая отвечает за запуск и мониторинг тасок.
  ServiceAccount - это то что другие сервисы используют для аутентификации перед другими сервисами. К примеру, Compute Engine использует сервис аккаунт для того, чтобы аутентифицироваться в Cloud Storage, и если он смог все таки подключиться, то это значит, что этому Service Account разрешено взаимодействовать с Cloud Storage. При создании кластера указывается определенный Service Account.
 PreemptibleNode стоит 1/5 RegularNode, но есть проблема с тем, что Google Cloud может удалить эти компьютеры, если ему будет это нужно.
 Возможно спокойно удалять, добавлять ноды.
 Вообще использование считается правильным, когда мы поднимаем кластер для какой-то джобы, и как она отработала, вырубаем кластер.
 Пишет логи в StackDriver.
 Есть Connectors to BigQuery, Cloud Storage, Cloud Bigtable.
 Чере cli передаются проперти, как --properties 'spark:spark.driver.maxResultSize = 2g, ...' Эти проверти только доступны либо через cli, либо через console.
 Можно ставить Initialization actions, они позволяют запускать скрипт во время старта кластера. Скрипт должен лежать в gs. 
 Worker должны иметь одну и ту же конфигурацию. Для использования PreemptibleNode, должно быть по крайней мере задействовано 3 машины.
 У User могут быть Viewer or Editor roles, а у Service account - Worker role.
 BigDL:
  Библиотека для запуска DeepLearning программ на Spark. 
 Secondary workers:
  1) Processing only — Secondary workers do not store data. 
  2) No secondary - worker-only clusters—Your cluster must have primary workers. 
  3) Machine type — Secondary workers use the machine type of the cluster's primary workers. 
  4) Persistent disk size — As a default, secondary workers are created with the smaller of 100GB or the primary worker boot disk size
 Autoscaling is not recommended for:
  HDFS: Autoscaling is not intended for scaling on-cluster HDFS. 
  YARN Node Labels: Autoscaling does not support YARN Node Labels, nor the property dataproc:am.primary_only due to YARN-9088. YARN incorrectly reports cluster metrics when node labels are used.
  Spark Structured Streaming: Autoscaling does not support Spark Structured Streaming (see Autoscaling and Spark Structured Streaming).
  Idle Clusters: Autoscaling is not recommended for the purpose of scaling a cluster down to minimum size when the cluster is idle.

DataFlow:
 Сервис для стриминговой и батч обработки данных, на основе ApacheBeam.
 Есть два вида данных, Bounded - сформированный набор данных and unbounded - стрим данных, который никогда не будет с компликтован.
 3Vs - Volume, Velocity, Variety.
 Под капотом то же самое что и в спарк, берет данные, разбивает их, выполняет вычисления и затем выдает результат. PCollection == RDD.

 Особенности:
  Входные данные автоматически ребаллансируются.
  Так же есть некий концепт Flexible scheduling, это когда бати джобу ставят в какую-ту временную рамку и затем выполняют с гарантией в промежуток 6 часов.
  Есть уже готовые к использованию AI паттерны.

 All features:
  Streaming Engine - передвигает часть вычислений с worker VMs and into the Dataflow service back end.
  Autoscaling - Autoscaling lets the Dataflow service automatically choose the appropriate number of worker instances required to run your job.
  Dataflow Shuffle - Service-based Dataflow Shuffle moves the shuffle operation, used for grouping and joining data, out of the worker VMs and into the Dataflow service back end for batch pipelines.
  Dataflow SQL - Dataflow SQL lets you use your SQL skills to develop streaming Dataflow pipelines right from the BigQuery web UI.
  Flexible Resource Scheduling (FlexRS)	- Dataflow FlexRS reduces batch processing costs by using advanced scheduling techniques, the Dataflow Shuffle service, and a combination of preemptible virtual machine (VM) instances and regular VMs. 
  Dataflow templates - Dataflow templates allow you to easily share your pipelines with team members and across your organization or take advantage of many Google-provided templates to implement simple but useful data processing tasks.
  Notebooks integration	- Iteratively build pipelines from the ground up with AI Platform Notebooks and deploy with the Dataflow runner.
  Inline monitoring - Dataflow inline monitoring lets you directly access job metrics to help with troubleshooting batch and streaming pipelines.
  Customer-managed encryption keys - You can create a batch or streaming pipeline that is protected with a customer-managed encryption key (CMEK) or access CMEK-protected data in sources and sinks.
  Dataflow VPC Service Controls - Dataflow’s integration with VPC Service Controls provides additional security for your data processing environment by improving your ability to mitigate the risk of data exfiltration.
  Private IPs - Turning off public IPs allows you to better secure your data processing infrastructure. 

 Pricing:
  Dataflow jobs are billed per second, based on the actual use of Dataflow batch or streaming workers. 

 Все начинается с Driver Programm, где мы определяем Pipeline, включающий в себя inputs, transforms and outputs, так же определяет опции, которые передаются пайплайну.
 Pipeline инкапсулирует всю работу приложения от начала до конца. При его создании, мы определяем где и как запускать этот pipeline. 
 Runner - это то, что выполняет pipeline. PCollection - это то, на чем оперирует pipeline. PCollection - выходные и выходные степы для каждого шага в рамках pipeline. 
 Transform - это операции, которые оперируют на PCollection, и в качесте результата возвращает новый PCollection. 
 Source/Sink - откуда/куда читаются данные (это просто куски кода которые определяют сорсы и синки).
 Есть такие же концепты, как Processing and Event time, работают так же как и в Spark.

 Windowing:
  Tumbling windows: Простой вид окон, при котором у нас имеется, агрегация данных, разделенная по какому-то промежутку времени.
  Hopping windows: окна, которые запускаются каждый какой-то промежуток и с каким-то определенным параметром окна.
  Session windows: окна, которые запускаются после каждого GapDuration. Session windowing assigns different windows to each data key. Tumbling and hopping windows contain all elements in the specified time interval, regardless of data keys.
  Watermarks - это гарантия того, что данные, которые пришли чуть позже поле времени окна, эти данные так же передаются в Window. 
  Triggers determine when to emit aggregated results as data arrives. By default, results are emitted when the watermark passes the end of the window.

 При работе с данными есть три составляющие, которые составляют основу работы с данными. Completeness, Low Latency and Cost. 
 FlumeJava - Это Java API построенный поверх MapReduce. Мы просто пишем вычисления, которые, будут выполняться на основе Cloud Dataflow.

 BatchPattern: 
  Creating Structured Data - создание структурированных данных, которые прогоняются одним большим батчем. (Найти top user за день).
  Time Based Window - мы разделяем данные на не большие порции и считаем уже результат на них. (Топ юзер за час).
  Sessions - это паттерн, при котором  коллектятся данные по сессиям, и считаются уже после того, как сессия была закончена. Но тут есть проблема с тем, чтобы взять реальные данные из-за проблем с переключением(Nightly Rollover).
 MillWheel - Streaming Computation, строит граф задач и выполняет их по инструкции 
  Element-Wise Transformations - аггрегация по window time.
 Time Skew - это когда данные приходят с запозданием. Watermark - это показатель того, на сколько запоздалые данные мы будем ждать.

 DataFlow:
  1) SDK for authoring programs.
  2) Fully managed system for running those programs.
  Имеет следующие преимущества:
   1) Graph Optimizer - fast and efficient.
   2) Smart Workers - Lifecycle management, autoscaling, rebalancing.
   3) Early Monitoring - integrated with cloud logging. 
  Целый граф выполняется как Single Unit. И каждая запись под собой несет не явный timestamp.

  PCollection:
   PCollection - это коллекция параллельных данных, трансформация над которыми ведет в новый PCollection.
   Element wise - Called a ParDo. Same thing is executed in parallel over and over. 
   Aggregating -  Multiple input into one output. 
   Composite - Sub graphs of other PCollections. 
  Backing store - это хранилище, откуда мы будем читать.

 Pipeline I/O: let you read data into your pipeline and write output data from your pipeline. An I/O connector consists of a source and a sink. 
 
 !!! Концепты DataFlow: Pipelines, PCollection, Transforms, ParDo, Pipeline I/O, Aggregation, UDF, Runner.

 StackDriver:
  На StackDriver мы имеем множество Pre-defined материк, такие как is_memory, total_memory_usage and etc. 
  При работе с Dashboard можно сохранять их как JSON.
  Resource Type - имя спрвиса (BigQuery, Cloud Dataflow)
  Metric - is the entity or item we want to monitor. (Number of queries or watermark age) 
  Runner - это среда, в которой pipeline работает.
  Resource Button - кнока на Stack Driver для мониторинга ресурсов
 A Dataflow regional endpoint stores and handles metadata about your Dataflow job, and deploys and controls your Dataflow workers.

 However, the Dataflow runner uses a different, private implementation of PubsubIO. This implementation takes advantage of Google Cloud-internal APIs and services to offer three main advantages: low latency watermarks, high watermark accuracy (and therefore data completeness), and efficient deduplication

Difference between Dataproc and Dataflow:
 Dataproc не пригоден для Streaming processing. В то время как Dataflow пригоден. Так же на Dataproc можно запускать SparkML и ML задачи, а на Dataflow только с помощью Cloud ML Engine. Iterative processing and notebooks is only for Dataproc.

Pub/Sub: 
 Message driven application, похожая на кафку. Так же есть топики, подписчики и паблишеры.
 Message attributes - это то, с чем приходят сообщения, они в себе несут k/v пары.
 Data processing - это зарузка данных, эх фильтрация, улучшение и выгрузка.
 Data analysis - это анализ на данных, группировка, сумма, среднее и другое.
 Самый главный концепт в message system есть скорость ответа (как быстро данные приходят и обрабатываются).
 Преимущества:
  - Managed real time processing system.
  - Supports one:one, many:one, many:many patterns.
  - Global avilability.
  - Low-latency ingest and delivery
  - On-demand scalability to millions of events/secs
 
BigTable:
 NoSQL database server. Спроектирован для работы с большим количеством данных. Очень подходит для часто изменяющихся данных, над большим ренджем ключей. 

Cloud Service: 
 Это сервис, который предоставляет нам услуги для разворачивания сервисов в cloud. С помощью специального сервисного аккаунта и специальных сервисов, появляется возможность разворачивать, скейилить ищи много чего с помощью лишь одно клика мыши.
 По факту мы лишь логинимся и предоставляем соответвующий доступ к сервис аккаунту.
 Клауд сервис позволяет нам коннектится к любому сервису из любого места и с любой платформы. Нам нужен лишь интернет, мы даже можем коннектиться с телефона.
 Так же сам сервис считает ресурсы который мы используем и выставляет нам счет, так же он в считанные минуты дает и забирает лишние и нет кластеры.
 SaaS - предоставляет приложения, которые работают в облаке.
 PaaS - предоставляет платформу на которой мы запускаем наши приложения.
 IaaS - предоставляет инфраструктуру на которой можно конфигурировать машины. 
 Deployment Mode: 
  Private Cloud - приватное облако внутри организации.
  Community Cloud - облако подаренное между каким-то коммьюнити.
  Public Cloud - публичное облако.
  
  Internal Cloud - облако внутри какой-то компании
  External Cloud - облако которое предоставляется провайдерами
  P.S. Если не хочется создавать серверную самому, просто создай ее на External, выделив часть компьютеров только для своих нужд.
  Если есть страх потерять данные, то мы какую-то часть deploy локально, а какую-то часть в облако. Даже если по началу покажется, что это дороже, занимать у кого-то компьютеры, то это не так, потому что не тратятся деньги на администрирование и поддержку. И платятся деньги только за моменты использования. Чаще всего провайдер гарантируют то, что данные не буду потеряны, так как fault tolerance.
 
 Cloud Service, в основе своей позволяют выполнять deвtributed processing. Даже если у вас имеется супер компьютер, ему будет сложнее вычислять чем многим компьютерам. Это проиходит тем образом, что у нас есть какой-то центральный руководитель, который распределяется распределением работы на компьютеры. По существу это и есть Destributed processing.

 Fault tolerance - это процесс при котором мы имеем возможность перераспределить нагрузку на других компьютерах, если какой-то пк упал.
 Клиент, подключаясь к кластеру, вводить ip целого кластера, не каждого компьютера отдельно, после чего уже внутри кластера это соединение будет соответсвенно обрабатываться. То есть один из компьютеров будет держать связь с клиентом и обрабатывать его запросы, если он упадет, другие пк возьмут его настройки и соединения. Так же компьютеры сообщают друг другу свою нагрузку, если нагрузка не равномерная, задачи будут распределяться.
 Состав Cloud Infrastructure:
  Bare Metal Hardware + Firmware - это слой, на котором расположились машины, которые работают как одна система (кластер).
  OS, которая работает на этих машинах.
  HyperVisor - это часть в инфраструктуре, которая отвечает за OS клиента.
  На SaaS мы имеем возможность запускать приложения, и сервис провайдер будет ответственен за предоставляемые OS.
  На PaaS мы имеем возможность выбрать у провайдера какую мы хотим систему с каким OS.
  На IaaS мы должны делать все сами, ведь со стороны провайдера нам дается лишь "железо".

 Security:
  Первым делом надо защищать инфраструктуру, потому что если у нас не будет защита на самом начальном уровне, то нет смысла идти дальше.
  На этом этапе будет описано множество слоев защиты, которые нужно применить к данным которые находятся в зоне нашей ответсвенности.
  1. Framework for Governance:
   Это набор документов, содержащие наборы инструкций и шагов, для защиты данных. Описано то, как работать на enterprise. Есть коллекция бизнес индустрий и что нужно делать для их защиты. К примеру, такими проблемами могут, землетрясения, качество компьютеров и другие физические риски, к примеру можно написать сырость, воздух и электричество. Нельзя при устроится нарушать закон. Воровать чьи-то идеи и тд, то есть если вы к примеру работаете с кредитными картами, то нужно соблюдать правила и закон работы с такого рода информацией.
   Через этот документ мы фактически объявляем набор правил, которым должен следовать работник. Мы их должны обучить при приеме на работу и в лучшем случае проверять знания каждый год. Если работник нарушит эти правила, то он будет уволен. Так же есть такой вид документа, описывающий процесс приема на работу.
  2. Risk management - это такой уровень секьюрит, при котором мы оцениваем все риски которые с нами могут произойти, этот процесс долгий и проходит за примерно 3 года.
   2.1 Risk Assessment - это разработка и фиксирование всех проблем, которые могут произойти на enterprise. Другими словами это предсказание будущего.  То есть описание реакции, к примеру на землятрясение или ураган, в описание еще входят возможный саботаж со стороны емплоеров или клиентов или проблемы с электричеством и обеспечением среды для техники. Зная все проблемы мы можем обеспечить защиту от проблем или построить само-восстанавливающуюся систему.
    При составлении нужно убедиться в том, что мы объединили все, что нам ценно и описали проблемы, которые могут с этим случиться. При составлении списка каждой вещи можно повесть какую-то оценку, к примеру, деньги. То есть "сколько мне денег приносит эта вещь и что я потеряю", и в зависимости от цены вещи, я должен предоставить соответствующую степень охраны от "плохих вещей".
    Есть три стадии Controls - Prevent, Response, Recovery.
   2.2. Risk Management - Management должен определить, что нужно делать чтобы избежать риск. Он принимает риски, предложенные на стороне Risk Assessment, и затем пишет к ним порядок действий. Самое главное еще это то, что если мы не можем исключить проблему, то мы ее должны как минимум задержать, чтобы было больше времени для того чтобы задетектить угрозу. Как только мы описали все контроллеры, нам стоит удостовериться в том что они правильно используются и то что мы их постоянно улучшаем.
  3. Securing the Infrastructure - процесс и активность для защиты enterprise. Подразумевает административный, физический и технический контроль. Вводит понятие ролей, ответственности и их принадлежности к ресурсам. Так же это предусматривает тренинг для новых юзеров и рефреш раз в год. Включает мониторинг наращений этих самых security и соответствующий алертинг. Метрики для мониторинга эффективности.
  CIA - это термин, обозначающий протекцию над данными(Confidentiality - данные всегда засекречены, Integrity - никаких потерь не будет, Availability - доступность данных только тогда когда они нужны).
   1. Confidentially 
    1.1 Access Permission - это способность давать пермишон на чтение/запись какому-то пользователю или вообще все запретить. При этом запрет как можно ставить как на сеть, так и на fs.
    1.2 Encryption - возможность энкриптить данные и давайть доступ только людям у которых есть ключ.
    1.3 DLP - ограничивает доступ участком определенного сегмента.
    1.4 Physical control - локальный ресрикт доступа к информации (закрыть доступ в комнату от посторонних людей).
   2. Integrity protection
    2.1 Access permission - Ограничить доступ
    2.2 Encryption -
    2.3 Physical control
   3. Integrity verification - хешит данные по хеш значениям, и если данные поменялись, то будет уже другой хеш, а это значит что данные нарушены. 
   4. Availability -  иметь отличный доступ к данным, в момент когда он запросил этот доступ. Fault-tolerant в данном случае о том, что, если даже какой-то компьютер упал, мы по прежнему можем достучаться до своих данных. Redundancy - говорит о том что мы имеем по меньшей мере 2 копии от нужных компонентов. Cloud service. Cluster Service - о том что мы имеем набор машин которые взаимодействуют друг с другом в одной сети и подхватывают нагрузки друг друга из-за hearbeat. RAID - созданы для саппорта fault-tolerant and redundancy. Здесь если несколько уровней RAID. Back-Ups -  спасет от удалений данных. Co-Location - создается два кластера, которые друг друга заменяют и поддерживают.
  4. Data Protection
   4.1 Physical Security - Закрытые двери, охранники и контроль доступа
   4.2 Network Security - Авторизация, аутентификация, фаерфол и другие
   4.3 System Security - Контроль за компьютерами, установка антивирусов, approved applications.
   4.4 Application Security - Защита приложения, то есть защита кода, code review, стнадарты дизайна.
   4.5 User Security - Дать пользователям какое-то соглашение какое они должны соблюдать
   4.6 Administrator Security - Это буквально роль которая может все, за ней нужен отдельный контроль.
   Под этим заголовком описывается то, как мы должны защищать так называема sensetive data: Business Intellectual property(patent, trade secret, R&D Data and etc.) and Personally Identifiable Information (Employee or Customer data - names, address, telephones, financial, biometric and etc.).
   4.7 Data Classification level - для того чтобы начать как-то классивицировать наши данные, нужно обозначить от 4 до 5 лейблов для данных (Secret, Top Secret, Unclassified, Public and etc.). Далее нужно определить критерий, то есть сколько мы потеряем денег, если эти данные будут утеряны. Утвердить уровни защищенности и доступа к разного рода ресурсам. И нанести лейблы на эти данные. Так же нужно заасайгнить роли юзерам.
   4.8 AAA 
    Authentication - удостоверение того что юзер это то кто он есть. (Mutuly Authentication) - это характеристика, которая описывает взаимную аутентификацию (юзера и сервера).
    Authorization - это процесс передачи/взятия привилегий на доступа к какому-лито ресурсу. Никогда не давайте слишком много привилегий одному пользователю.
    Audit - слежка за активностью пользователя.
  5. System and Data Management:
   Рекомендации по установки серверов:
    1. Ограничить число запущенных сервисов до 1 или 2.
    2. Делать патчи.
    3. Отключать или удалять не используемые приложения.
    4. Поставить минимальным людям и минимальный доступ к данным.
    5. Установить антивирусы и другие анти- программы (держать их обновленными).
    6. Установить утилиты которые будут следить за состоянием приложений и выполнять обновления их.
    7. Удалить административные тулы и утилиты.
    8. Выполнять конфигурационные и vulnerability scan.
    9. Вести журнал действий.
    10. Пользоваться тулой, которая будет иметь возможность читать логи и определять нарушения.
   Configuration control:
    Это является требованием к письменному контролю всей системы. То есть описание ОС, приложений, руководства и тд. Так же вносить все изменения только через Approve.
   6. Security Awareness Training:
    Каждый работник должен пройти тренинг: onboarding, At least annually, significant changes to environment. 
    Дополнительный тренинг так же должен быть для пользователей, которые наделяются дополнительными правами: Administrators, root. Remote user - laptop, wireless user and telecommuters, and last, Access to sensitive data or large amounts of data.
    Восстановительный тренинг для тех кто нарушил права.
    Так же сюда входят safty, fire and CPR тренинги. Описание Security technology(VPN). Laws, procedures, regulations, applicable polices and etc. Так же нужно предупредить что пользователей за нарушение даже можно наказать законом. Надо научить пользователей мониторить и репортить о всех нарушениях, это может нам помочь. Назначений ответсвенностей и ролей, так же являются не отъедаемой частью секьюрити (ответственных за пожарную безопасность и другие части безопасности).
   7. User Provisioning: 
    Под собой это подразумевает возможность передавать роли пользователям, создавать или отнимать. Так же создание/удаление пользователей. Процедура назначения роли пользователю должна быть отдельной процедурой, обёрнутой в форму и имеющей Approval и соответствовать policy.
    Перед приемом на работу должна быть обязательная процедура: собеседования, резюме, предыдущей работы, умения и образования. Так же полезно знать был ли он осужден за что, то и имеет ли долги.
    И конечно же надо помнить, что и пользователя должен быть самый минимальный набор привилегий.
    Как юзер будет подтвержден, мы должны установить надлежащий уровень привилегий и контроля.
    Если у пользователя присутствует высокий уровень привилегий, его аукнут нужно обвесить Multi-Factor authentication.
    Удаленный доступ нуждается в дополнительной защите.
    Нужно задекларировать где может использоваться ресурсы, ведь телефон, к примеру, можно легко украсть и получить доступ к данным.
    Требуется специальный контроль за людьми с большими привилегиями.
    Следить за не зарегистрированным доступом и злоупотреблением привилегий.
    Нельзя давать слишком иного привилегий.
   8. Monitoring, Auditing, Response and Enforcement.
    Monitoring - непрекращающийся, рутиный процесс.
    Auditing - целенаправленное слежение.
    Если не следить, то аномалии никогда не будут выявлены.
    Так же лучше создать метрики работы секьюрити, ведь так мы сможем понять эффективность подхода.
    При наказании нужно быть объективным, то есть все, не зависимо от должности получают одно и то же самое наказание.
   9. Incident Responce - это люди и средства, предназначенные для предотвращения или восстановления после инцидента.
 
 Preparing for cloud use:
  1. Framework for Governance - При выходи в облако, требуется дописать новые документы по правилам использования, наказаниям. При этом все те же права которые были применены на внутреннем хранилище, эти же права должны быть приняты на external. По соглашениям cloud provider обязан относится бережно к данным, которые мы ему передаем. Так же заключается договор с cloud provider, и если он не выполняет свои обязательства и из-за него страдают пользователи, то он должен нести за это ответственность. Для этого как раз таки нам нужно строгое заключение договора.
   При разворачивании нужно учитывать факт Integrity, Avalibility and Consistency данных. Идентификация юзеров и системы, которая может получать доступ к системе. Определить системы и приложения имеющие доступ к данным. И последнее, нужно понимать какие данные мы хотим перемещать в облако, а какие хотим держать локально. При выборе системы нужно ясно понимать что нам нужно(сколько памяти, доступность, регионы и какие мощности).
  2. Для подготовки данных к облаку нужно провести их нормализацию. Так же нужно привести вид данных к однородному виду. Помои данных нужно настроить авторизацию и аутентификацию. Важной частью является договорённости о том, что ваша важная дата никуда не пропадет. И последнее, требуются security tool для мониторинга и защиты данных и наличие encryption key и аозиожности им управлять.
  3. Следует ограничить набор данных, которые можно отправить в cloud. К примеру, мы можем определять тип данных по header or footer, то есть какие данные проходят, а какие нет. Помимо этого следует вообще контролировать весь поток данных, который проходит через облако. Внимательно нужно относиться к удалению. Потому, что даже удалённые данные можно восстановить по средством того, что данные не стираются с памяти, их всех следует переписать.
  4. Network Enterprise connect Zone - это часть сети, которая отвечает за коннекшон, авторизацию и определения устройства, ее следует рассматривать как еще один уровень защиты.
  5. Очень нужно внимательно следить за тем, на сколько защищены ваши виртуальные компьютеры, так как в cloud может быть несколько провайдеров, которые так же сидят в этом кластере. Не менее важно писать максимально секьюрный код.
  6. Для того, чтобы секюрить приложение в SaaS, мы можем использовать cloud секьюрити и outsourced cloud секьюрити. Нужно использовать AAA. Web and Email Security. DLP system - следит за тем, чтобы данные не потерялись и что данные не были порчены. Настроить подходящий encryption уровень для наших данных. Network security. Security assessment, сюда входит вся проверка секьюрности приложений.
  7. И последнее, при выборе специфичного cloud провайдера, следите за тем, чтобы те, кто являются провайдерами Клауд провайдера выполняли то, чего обязались. Далее удостоверьтесь в том, что кладу провайдер имеет подходящую атентификацию, например, что-то в роде токена. Вам вероятнее будет интересно узнать, какие сертификации имеет cloud provider, вот некоторые из них: SAS 70 Type II, ISO 27000 series and COBIT. Обязательно нужно рассматривать историю  cloud provider'a для того, чтобы знать кому вы доверяете данные. И в заключение, хорошим шагом бы было прийти к cloud провайдеру и узнать больше о построении их security.

 Cloud Service Agreement: это набор договоренностей, которые CSP должен соблюдать. CSP Должен иметь письменное удостоверение в том, что с нашими данными нищенки не сучится и он за всем следит, так же CSP должен соответствовать Cloud Service Requrements. Пользователь должен быть уверен, что CSP ведет честную игру и что пользовательское приложение и данные в какой-т момент времени не исчезнут. Если произошли какие-то сбои, то пользователь GDP должен быть немедленно об этом оповещен и этот сбои должен быть как можно быстро устранены.
  CSA - включает в себя то, что мы будем использовать: SaaS, PaaS or IaaS. Как много нам надо машин и мощностей, кто будет ответственен за HW/SW maintenance. Обязательно к обсуждению Up-Time (время, которое определяет то, сколько сервис может находится в отключке). Так же обсуждается Redundancy и Recovery(сколько данных мы можем потерять, как часто делать синк данных). 
  При обсуждении соглашения, первым делом обговаривается то, что CSP обязуется защищать наши данные и никогда их не открывать третьим лицам. Так же обсуждается ownership, то есть никто, кроме как создателя данных никогда не будет иметь доступ к этим данным, что бы не случилось. Access - последняя в тройке обсуждения, термин говорящий о том, что пользователь будет имееть дсотуп ко своим данным, что бы не случилось. CSP обязуется соблюдать закон и если он его нарушил, то так же должны быть обговорены наказания.
  Data Protection and Redundancy. Data at rest - вы должны быть уверенны что ваши данные не попадут в чужие руки, а что ваши машины и сеть защищены от других пользователей. Data in transit - защита данных при передаче (VPN, SSL and TLS). Data being processed - защита данных так же тут важна, суть является в том, что должна быть уверенность того что кластеризации который вы используете он только ваш, а если ивы его покидаете, то будьте уверенны в том, что не осталось следов после ваше обработки. Так же под эту тему попадете термин RPO, то есть та точка во времени, до которой потеря данных будет не критична, то есть тут, мы можем запускать запланированный бекап. RTO - термин обозначающий то, на сколько критичен таймаут при бекапе. Над всегда находить компромис между RTO and RPO.
  При хранении данных в облаке их следует дублировать, ведь таким образом мы сможем добиться их сохранности, так как в случае падения одного, второй просто возьмет копию. Так же в этом случае полезно было вести журнал транзакций, который позволит записывать все что мы делаем с данными. При этом все равно нужно делать бэкапы, потому что если пройдет какой-то вирус, то заразятся оба компьютера, а так сможете восстановиться с бекапа. Хорошей практикой будет хранить данные в разных регионах, благодаря чему, все что случиться с первым регионом, не случиться со вторым. Помимо всего, не должно быть проблем с транспортировкой данных, все форматы должны совпадать и данные должны доставляться.
  System Fault Tolerance and Redundancy: в овервью все знакомый принцип, у нас есть кластер, который содержит в себе несколько машин, которые коммуницируют друг с другом. Каждый компьютер хранит информацию о подключенных к нему сессий, и если компьютер упал, то другие компьютеры в этом кластере должны свободно взять сессии, которые привязаны с упавшему компьютеру, и начать их хендлить, со стороны такого рода обработка для пользователя будет незаметен и приложения пользователя продолжат так же работать без ошибок. VM Migration - термин, обозначающий миграцию машин с одного кластера на другой в тех случаях, когда кластер один слабо нагружен, а другому нужны ресурсы. Так же для поддержки системы поможет наличие двух power grid, то есть если один из них упадет, вы немедленно переключаетесь на другой и продолжаете работать, так же можно купить генераторы.
  Connectivety fault tolerance: Должна присутствовать поддержка нескольких путей, то есть если мы подключились к облаку, то мы должны быть уверены в том, что если на облаке отпадет connection, то там будет еще несколько путе дотянуться до нашего сервиса. Так же скорость передачи данных должна быть достаточной, чтобы чувствовать себя комфортно. Так же CSP обязаны предоставить аутентификешион механизмы. CSP обязан поддерживать систему, которая будет определять кто к какому ресурсу через сеть имеет право достучаться.
  Notifications and Penalties: CSP обязан документировать какие компютеры он использует, с какими ОС и какими конфигурациями, так же он обязан следить за этой конфигурацией, чтобы быть уверенным что сегодня компьютер сконфигурирован правильно и ничего не нарушено. Каждое изменение в конфигурацию должен проходить через change approval. Так же обязаны быть описаны Security Risks, с описанием того, какие риски (физические или технические) присутствуют. Ко всему этому должны быть приписаны penalties, то есть что будет делать CSP если все таки проблема произойдет. Так же CSP в случаях опасности моим данным обязан меня нотифицировать. Могут быть финансовые penalties, как например снятия некой части денежной аренды.
  CSP Prudent Management: CSP обязан мониторить ситуацию в облаке и в датацентрах, чтобы мгновенно определять всяческие проблемы и нарушения, чтобы устранять их на сколько можно быстро. Если случился какой-то катаклизм, CSP обязан мгновенно на него ответить в согласии с регламентом. Если какая-то проблема произошла то CSP обязан нотифицировать нас об этих проблемах. Если CSP восстанавливается после проблем, мы также обязаны как-то отвечать на эти проблемы.
  Monitoring the CSP: последняя форма безопасности работы с CSP. Клиент должен иметь возможность видеть что делает CSP, следить за его работой, за работой сервисов, следаить не только за юзерами клиентского приложения, но так же и за работой cloud администраторов. Так же клиент может посмотрен как защищены его данные в жизни, то есть на сколько хорошо защищено серверное здание.

 Staying Secure while using Cloud Service: это набор действий, которые позволят нам секьюрно пользоваться облаком.
  Cautious implementation of Cloud Service: если мы уже защитили данные на уровне архитектуры и Preparing for cloud use, то сейчас мы должны детектить все опасности связанные с нежелательной загрузкой данных в наше облако и алертить об этом. Так же может помочь постепенная заргрузка, то есть сначала грузить не защищенные данные, потом важные (лейблы на данные уже были повешены).
  Onsite inspection, auditing, and testing: тут для того чтобы быть уверенным в том что наши данные всегда будут в безопасности требуется постоянно ревьювить то, на сколько честно CSP соблюдает соглашение по управлению physical environment. Мы должны иметь право следить за работой администрации на стороне CSP, помимо слежки за пользователями нашей платформы. Так же нужно тестить то что все секьюрити функции работают и что у нас подобающим образом работает восстановление потерянных данных. 
  Review of Cloud metrics: CSP обязан поставлять нам метрики о том, что у нас происходит, что нужно улучшить или какие опасности есть. Так же должны иметь возможность отслеживать то, что делает наш пользователь (пользователь ведет себя подозрительно или пытается достучаться до ресурса, которые для него запрещен). Так же мы обязаны знать, соблюдает ли uptime договоренности CSP.
  Incident responce: Каждый раз когда что-то происходит плохое в клауде, CSP должен оповещать нас о случившемся, и ме обязаны как-то противостоять этой проблеме. После каждого ицилента мы должны заревьювит то что произошло и понять что нам делать в следующий раз, чтобы избежать эту проблему или уменьшить последствия которые она принесла.
  Key escrow: подразумевает под собой репозиторий ключей к данным, это пожалуй самый защищенный репозиторий, мы так же должны иметь возможность восстановить ключи.
  Agreement enforcement: Клиент должен мониторить CSP насчет того что он выполняет все соглашения. Каждое нарушение должно иметь агрессивный ответ. Если договориться не получается нужно пользоваться законом. Рассмотреть перейти на другой CSP, если этот не соблюдает правила.
  Cloud user monitoring and policy enforcement: каждый юзер должен иметь представление о том, какие есть правила и что будет за их нарушение. Так же клиенту будет очень полезно мониторить user активность.
  
 CMEK - Customer-managed encryption keys
 HSM - Hardware Security Module
 CSEK - Customer-Supplied Encryption Keys
 EKM - Cloud External Key Manager
 GCP не дает выбора энкриптить данные или нет. По дефолту, все данные копируются и Google делает все за нас. CMEK - это возможность самому менеджить свои ключи, то есть вы сами определяете их конфигурацию и то, как он будет защищать данные сервиса. CSEK - это возможность юзеру самому поставлять ключ, который будет использоваться гуглом для того, чтобы кодировать свои данные, этот ключ надо будет поставляю вместе с API call. 
  HSM -  это девайс, который выполняет энкрипт и декрипт данных. Его преимущества в том, что люди могут создавать ключи в нем и быть уверенны в том, что эти ключи никогда от туда никуда не денутся. Так же будет варнинг если произойдет попытка достать ключи. Так же этот девайс сертифицирован. Патчи автоматически применяются без задержки. Ключи не доступны не откуда, извне HSM. Ключи в HSM привязаны к одному региону, то есть операции над корчме можно совершать только в пределах региона в котором он был создан. Так же есть возможность для импорта ключей, в HSM.
  Дефолтная security Model работает следующим образом: дата загружается в Гугл, разбивается на части и каждая часть защищается своим ключом, затем эти данные распределяются в Гугл и харянятся там вместе с ключами. 
  CMEK - Позволяет защищать данные в других сервисах через HSM, саппортится на BQ, CE, CS, Dataproc. Защита данных происходит таким образом, что помимо шага, описанного выше, присходит обертка ключа с помощью пользовательского ключа (Key Encryption Key). KEK защищаются и управляется через KMS. Так же KMS хранит и мониторит, кто и когда подключался к нашим зашифрованным данным. Так же не важно где находится ключ, в приложение или в HSM. Есть ограничение при создании ключа, ключи должны быть находиться в одном и том же регионе. CMEK поддерживается в BigQuery (уровень таблиц), Dataproc (уровень кластера), Cloud Storage (уровень бакета или объекта), Persistent Disk (по дискам).
  EKM - Это возможность оперировать и хранить ключи не в GCP, а где-то извне. Каждый доступ к ключу будет осуществляться как API call к внешнему сервису.

 IAM: Это сервис который позволяет добавить привелегии или отнять у ролей для определенных клауд сервисов. Так же преследует принцип наименьших привилегий, который позволяет давать ровно столько разрешения, сколько надо для роли и не каплей больше.
  Модуль доступа состоит из 3-х частей:
   1. Member - member может быть: Google Account, service account, Google group, Google Workspace or Cloud Identity. Идентификацией служит email address или domain name.
   2. Role - это коллекция разрешений, Permissions determine what operations are allowed on a resource. When you grant a role to a member, you grant all the permissions that the role contains.
   3. Policy - The IAM policy binds one or more members to a role.
  Concept - когда пользователь пытается достучаться до какого-то сервиса, первым делом смотрится его IAM Role. 
  Некоторые сервисы поддерживают возможность давать разрешение не только на уровне проекта, но так же на более гранулярном уровне, к примеру, давать разрешение на чтение только к конкретному бакету.
  Permissions determine what operations are allowed on a resource. In the IAM world, permissions are represented in the form of service.resource.verb, for example, pubsub.subscriptions.consume. Обычно разрещения совпадают 1 к 1 с REST API method, уоторый они выставляют. For example, if you use Pub/Sub, and you need to call the topics.publish() method, you must have the pubsub.topics.publish permission for that topic. 
  A role is a collection of permissions. You cannot grant a permission to the user directly. Instead, you grant them a role. When you grant a role to a user, you grant them all the permissions that the role contains.
  Есть следующие виды ролей:
   Basic roles: Roles historically available in the Google Cloud Console. These roles are Owner, Editor, and Viewer.
   Predefined roles: Roles that give finer-grained access control than the basic roles. For example, the predefined role Pub/Sub Publisher (roles/pubsub.publisher) provides access to only publish messages to a Pub/Sub topic.
   Custom roles: Roles that you create to tailor permissions to the needs of your organization when predefined roles don't meet your needs.
  Policy:
   You can grant roles to users by creating an IAM policy, which is a collection of statements that define who has what type of access. A policy is attached to a resource and is used to enforce access control whenever that resource is accessed. An IAM Policy object consists of a list of bindings. A Binding binds a list of members to a role.
  Существует следующая иерархия в GCP IAM:
   The organization is the root node in the hierarchy.
   Folders are children of the organization.
   Projects are children of the organization, or of a folder.
   Resources for each service are descendants of projects.
  Policy которые были установлены выше чем ресурс, наследуется ресурсом и суммируются, так же прилагаются сами перпишоны к ресурсу.
  Важно то, что те разрешения которые были объявлены выше имеют приоритет.
  Service accounts differ from user accounts in a few key ways:
   Service accounts do not have passwords, and cannot log in via browsers or cookies.
   Service accounts are associated with private/public RSA key-pairs that are used for authentication    to Google.
   You can let other users or service accounts impersonate a service account.
   Service accounts are not members of your Google Workspace domain, unlike user accounts. For example, if you share assets with all members in your Google Workspace domain, they will not be shared with service accounts. Similarly, any assets created by a service account cannot be owned or managed by Google Workspace or Cloud Identity admins. This doesn't apply when using domain-wide delegation, because API calls are authorized as the impersonated user, not the service account itself.
  



  




















